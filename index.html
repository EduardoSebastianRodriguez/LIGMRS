<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-10550309-8"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-10550309-8');
</script>

<script src="http://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
    body {
        font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
        font-weight:300;
        font-size:18px;
        margin-left: auto;
        margin-right: auto;
        width: 1100px;
    }

    h1 {
        font-weight:300;
    }

    .disclaimerbox {
        background-color: #eee;
        border: 1px solid #eeeeee;
        border-radius: 10px ;
        -moz-border-radius: 10px ;
        -webkit-border-radius: 10px ;
        padding: 20px;
    }

    video.header-vid {
        height: 140px;
        border: 1px solid black;
        border-radius: 10px ;
        -moz-border-radius: 10px ;
        -webkit-border-radius: 10px ;
    }

    img.header-img {
        height: 140px;
        border: 1px solid black;
        border-radius: 10px ;
        -moz-border-radius: 10px ;
        -webkit-border-radius: 10px ;
    }

    img.rounded {
        border: 1px solid #eeeeee;
        border-radius: 10px ;
        -moz-border-radius: 10px ;
        -webkit-border-radius: 10px ;
    }

    a:link,a:visited
    {
        color: #1367a7;
        text-decoration: none;
    }
    a:hover {
        color: #208799;
    }

    td.dl-link {
        height: 160px;
        text-align: center;
        font-size: 22px;
    }

    .layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
        box-shadow:
                0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
                5px 5px 0 0px #fff, /* The second layer */
                5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
                10px 10px 0 0px #fff, /* The third layer */
                10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
                15px 15px 0 0px #fff, /* The fourth layer */
                15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
                20px 20px 0 0px #fff, /* The fifth layer */
                20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
                25px 25px 0 0px #fff, /* The fifth layer */
                25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
        margin-left: 10px;
        margin-right: 45px;
    }


    .layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
        box-shadow:
                0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
                5px 5px 0 0px #fff, /* The second layer */
                5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
                10px 10px 0 0px #fff, /* The third layer */
                10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
        margin-top: 5px;
        margin-left: 10px;
        margin-right: 30px;
        margin-bottom: 5px;
    }

    .vert-cent {
        position: relative;
        top: 50%;
        transform: translateY(-50%);
    }

    hr
    {
        border: 0;
        height: 1.5px;
        background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
    }
</style>

<html>
  <head>
        <title>Learning to Identify Graphs from Node Trajectories in Multi-Robot Networks</title>
        <meta property="og:title" content="LIGMRS" />
        <meta property="og:image" content="" />
        <meta property="og:url" content="" />
      <style>
code {
  font-family: Consolas,"courier new";
  color: darkcyan;
  background-color: #f1f1f1;
  padding: 2px;
  font-size: 105%;
}
</style>
  </head>

  <body>
    <br>
    <center>
    <span style="font-size:42px">Learning to Identify Graphs from Node Trajectories in Multi-Robot Networks</span>
    
    </center>

    <br><br>
      <table align=center width=900px>
       <tr>
         <td align=center width=900px>
         <center>
         <span style="font-size:20px"><a href="https://eduardosebastianrodriguez.github.io/">Eduardo Sebastian</a>,
             <a href="https://thaipduong.github.io/">Thai Duong</a>,
             <a href="https://natanaso.github.io/">Nikolay Atanasov</a>,
             <a href="https://sites.google.com/unizar.es/eduardo-montijano">Eduardo Montijano</a> and
             <a href="https://webdiis.unizar.es/~csagues/">Carlos Sagues</a>
         </span>
         </center>
         </td>
     </tr>
    </table>

    <br>

    <table align=center width=800px>
       <tr>
        <td align=left width=350px>
        <center>
        <span style="font-size:20px">Departamento de Informatica e Ingenieria de Sistemas, <br> Universidad de Zaragoza<br/></span>
        </center>
        </td>
        <td align=right width=100px>
        <center>
        <span style="font-size:20px"></span>
        </center>
        </td>
        <td align=right width=350px>
        <center>
        <span style="font-size:20px">Department of Electrical and Computer Engineering, <br> University of California, San Diego<br/></span>
        </center>
        </td>
     </tr>
    </table>

    <br>

    <table align=center width=700px>
       <tr>
        <td align=center width=100px>
        <center>
        <span style="font-size:20px"><a href="https://sites.bu.edu/mrs2023/">Accepted at IEEE MRS 2023</a></span>
        </center>
        </td>
     </tr>
    </table>


    <br>

    <table align=center width=300px>
     <tr>
       <td align=center width=100px>
       <center>
       <span style="font-size:20px"><a href="https://arxiv.org/abs/2307.04374">[Paper]</a></span>
       </center>
       </td>
       <td align=center width=100px>
       <center>
       <span style="font-size:20px"><a href="https://github.com/EduardoSebastianRodriguez/LIGMRS">[Code]</a></span>
       </center>
       </td>

   </tr>
  </table>




            <br>
            

            <br>
            The graph identification problem consists of discovering the interactions among nodes in a network given their state/feature trajectories. This problem is challenging because the behavior of a node is coupled to all the other nodes by the unknown interaction model. Besides, high-dimensional and nonlinear state trajectories make difficult to identify if two nodes are connected. Current solutions rely on prior knowledge of the graph topology and the dynamic behavior of the nodes, and hence, have poor generalization to other network configurations. To address these issues, we propose a novel learning-based approach that combines (i) a strongly convex program that efficiently uncovers graph topologies with global convergence guarantees and (ii) a self-attention encoder that learns to embed the original state trajectories into a feature space and predicts appropriate regularizers for the optimization program. In contrast to other works, our approach can identify the graph topology of unseen networks with new configurations in terms of number of nodes, connectivity or state trajectories. We demonstrate the effectiveness of our approach in identifying graphs in multi-robot formation and flocking tasks.
            <br><br>

      <hr>
            <table align=center width=1000>
             <center><h1>Paper</h1></center>
                <tr>
                  <td><a href="https://arxiv.org/abs/2307.04374.pdf"><img style="height:300px" src="./resources/thumbnail.png"/></a></td>
                  <td><span style="font-size:14pt">Eduardo Sebastian, Thai Duong, Nikolay Atanasov, Eduardo Montijano and Carlos Sagues<br><br>
                           Learning to Identify Graphs from Node Trajectories in Multi-Robot Networks<br><br>
                           IEEE MRS 2023.<br><br>
                      <a href="https://arxiv.org/abs/2307.04374.pdf">[pdf]</a> &nbsp; &nbsp;
                    </td>
              </tr>
            </table>

      <hr>
<!--
            <table align=center width=900>
             <center><h1>Poster</h1></center>
                <tr>
                  <td><center><a href="./resources/Poster.pdf"><img style="height:300px" src="./resources/Poster.png"/></a></td>
              </tr>
            </table>
-->
<!--

      
      
                <hr>
                <center><h1>Overview</h1></center>
                <table align=center width=900px>
                    <tr>
                        <td width=600px>
                          <center>
                            <div class = "video">
                                    <iframe width="800" height="480" src="https://www.youtube.com/embed/XtJ4peLyLOg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                           </div>
                        </center>
                        </td>
                    </tr>
                </table>
                <br>
                -->
<!--
    <hr>
                <center><h1>Presentation at IEEE ICRA 2023</h1></center>
                <table align=center width=900px>
                    <tr>
                        <td width=600px>
                          <center>
                            <div class = "video">
                                    <iframe width="800" height="480" src="https://www.youtube.com/embed/_ZmhHZnS9n8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                           </div>
                        </center>
                        </td>
                    </tr>
                </table>
                <br>
        -->

          <hr>
          <table align=center width=550px>
            <table align=center width=800>
             <center><h1>Details and Multimedia</h1></center>
                <tr>
                    <br>
            <br>

            <table align=center width=1000px>
                <tr>
                    <td width=1000px>
                      <center>
                          <a href="./resources/architecture.png"><img src = "./resources/architecture.png" width="1000px"></img></href></a><br>
                    </center>
                    </td>
                </tr>
                    <td width=1000px>
                      <center>
                          <span style="font-size:18px"><i> A time-varying graph with unknown connectivity and node dynamics generates a dataset of trajectories (left). A self-attention encoder generates node trajectories in a feature space and computes the regularization parameters. These outputs are the input for an adjacency matrix optimization problem (middle). A fast strongly convex optimization algorithm identifies the weighted adjacency matrix that best describes the observed node trajectories (right).</i>
                    </center>
                    </td>
                </tr>
            </table>
                    <br>
            <br>

            <table align=center width=1000px>
                <tr>
                    <td><a href="./resources/learning_module.png"><img style="height:500px" src="./resources/learning_module.png"/></a></td>
                    <td><a href="./resources/optimization.png"><img style="height:400px" src="./resources/optimization.png"/></a></td>
                </tr>
            </table>

            <table align=center width=1000px>
                <tr>
                     <td width=1000px>
                      <center>
                          <span style="font-size:18px"><i>The state trajectory encoder (left) consists of four blocks: (i) a fully connected layer that encodes each individual state to a feature state of a single dimension; (ii) a self-attention layer that finds the relationships among features; (iii) a fully connected series of layers that finds the distances among feature trajectories; and (iv) two separate fully connected layers to find the regularization parameters for the subsequent graph identification optimization.</i>
                    </center>
                    </td>
                </tr>
            </table>

            <table align=center width=1000px>
                <tr>
                     <td width=1000px>
                      <center>
                          <span style="font-size:18px"><i>Besides the global convergence to the best graph topology in the smooth state trajectory sense, Algorithm 1 (right) is efficient to compute so, at each instant, sufficient iterations can be run to ensure convergence to the weighted adjacency matrix that best describes the node state trajectories defined over the Euclidean space. </i>
                    </center>
                    </td>
                </tr>
            </table>

                <br><br>
            <table align=center width=1000px>
               <tr>
                 <td align=center width=1000px>
                 <center>
                 <span style="font-size:20px"><a href="./resources/ground_truth_50.png"><img src = "./resources/ground_truth_50.png" width="230px"></img></href></a>
                     <a href="./resources/discovered_50.png"><img src = "./resources/discovered_50.png" width="230px"></img></href></a>
                     <a href="./resources/difference_50.png"><img src = "./resources/difference_50.png" width="230px"></img></href></a>
                     <a href="./resources/bool_difference_50.png"><img src = "./resources/bool_difference_50.png" width="230px"></img></href></a>
                 </span>
                 </center>
                 </td>
             </tr>
            </table>
            <table align=center width=1000px>>
                <tr>
                    <td width=600px>
                      <center>
                          <span style="font-size:18px"><i>Results from a multi-robot formation tasks, from left to right: ground-truth weighted adjacency matrix, identified weighted adjacency matrix, difference between ground-truth and identified matrices, and the same difference but with a threshold on the weights that are small so that they are zero and one otherwise. It is seen that the learned neural network is able to accurately identify all the weights, except some outliers that explain the differences in color scale. </i>
                    </center>
                    </td>
                </tr>
            </table>

                <br><br>
            <table align=center width=1000px>
               <tr>
                 <td align=center width=1000px>
                 <center>
                 <span style="font-size:20px"><a href="./resources/ground_truth_20.png"><img src = "./resources/ground_truth_20.png" width="230px"></img></href></a>
                     <a href="./resources/discovered_20.png"><img src = "./resources/discovered_20.png" width="230px"></img></href></a>
                     <a href="./resources/difference_20.png"><img src = "./resources/difference_20.png" width="230px"></img></href></a>
                     <a href="./resources/bool_difference_20.png"><img src = "./resources/bool_difference_20.png" width="230px"></img></href></a>
                 </span>
                 </center>
                 </td>
             </tr>
            </table>
            <table align=center width=1000px>
               <tr>
                 <td align=center width=1000px>
                 <center>
                 <span style="font-size:20px"><a href="./resources/ground_truth_40.png"><img src = "./resources/ground_truth_40.png" width="230px"></img></href></a>
                     <a href="./resources/discovered_40.png"><img src = "./resources/discovered_40.png" width="230px"></img></href></a>
                     <a href="./resources/difference_40.png"><img src = "./resources/difference_40.png" width="230px"></img></href></a>
                     <a href="./resources/bool_difference_40.png"><img src = "./resources/bool_difference_40.png" width="230px"></img></href></a>
                 </span>
                 </center>
                 </td>
             </tr>
            </table>
            <table align=center width=1000px>
               <tr>
                 <td align=center width=1000px>
                 <center>
                 <span style="font-size:20px"><a href="./resources/ground_truth_60.png"><img src = "./resources/ground_truth_60.png" width="230px"></img></href></a>
                     <a href="./resources/discovered_60.png"><img src = "./resources/discovered_60.png" width="230px"></img></href></a>
                     <a href="./resources/difference_60.png"><img src = "./resources/difference_60.png" width="230px"></img></href></a>
                     <a href="./resources/bool_difference_60.png"><img src = "./resources/bool_difference_60.png" width="230px"></img></href></a>
                 </span>
                 </center>
                 </td>
             </tr>
            </table>
            <table align=center width=1000px>>
                <tr>
                    <td width=600px>
                      <center>
                          <span style="font-size:18px"><i> The neural network is only trained with a single trajectory of a single multi-robot formation graph. The neural network generalizes to different numbers of robots and formation configurations with the same density of connections, also called edge density. </i>
                    </center>
                    </td>
                </tr>
            </table>
            <table align=center width=1000px>
               <tr>
                 <td align=center width=900px>
                 <center>
                 <span style="font-size:20px"><a href="./resources/analysis_n.png"><img src = "./resources/analysis_n.png" width="900px"></img></href></a>
                 </span>
                 </center>
                 </td>
             </tr>
            </table>
            <table align=center width=1000px>>
                <tr>
                    <td width=600px>
                      <center>
                          <span style="font-size:18px"><i> Multi-robot formation task: Mean Absolute Error between ground-truth and identified weighted adjacency matrices as a function of the number of robots and edge density. Each configuration is run 20 times, computing the mean and standard deviation. Diamond dashed lines are the state-of-the-art (reference [28] in the paper), whereas the circle solid lines are ours. Our proposed approach surpasses the state-of-the-art in one order of magnitude for all the configurations, considering that the neural network has only been trained with a single graph and associated trajectory.</i>
                    </center>
                    </td>
                </tr>
            </table>


                <br><br>
            <table align=center width=1000px>
               <tr>
                 <td align=center width=1000px>
                 <center>
                 <span style="font-size:20px"><a href="./resources/ground_truth_50_01.png"><img src = "./resources/ground_truth_50_01.png" width="230px"></img></href></a>
                     <a href="./resources/discovered_50_01.png"><img src = "./resources/discovered_50_01.png" width="230px"></img></href></a>
                     <a href="./resources/difference_50_01.png"><img src = "./resources/difference_50_01.png" width="230px"></img></href></a>
                     <a href="./resources/bool_difference_50_01.png"><img src = "./resources/bool_difference_50_01.png" width="230px"></img></href></a>
                 </span>
                 </center>
                 </td>
             </tr>
            </table>
            <table align=center width=1000px>
               <tr>
                 <td align=center width=1000px>
                 <center>
                 <span style="font-size:20px"><a href="./resources/ground_truth_50_04.png"><img src = "./resources/ground_truth_50_04.png" width="230px"></img></href></a>
                     <a href="./resources/discovered_50_04.png"><img src = "./resources/discovered_50_04.png" width="230px"></img></href></a>
                     <a href="./resources/difference_50_04.png"><img src = "./resources/difference_50_04.png" width="230px"></img></href></a>
                     <a href="./resources/bool_difference_50_04.png"><img src = "./resources/bool_difference_50_04.png" width="230px"></img></href></a>
                 </span>
                 </center>
                 </td>
             </tr>
            </table>
            <table align=center width=1000px>>
                <tr>
                    <td width=600px>
                      <center>
                          <span style="font-size:18px"><i> Multi-robot formation task: Our approach moderately generalizes to other edge densities during evaluation because the training set only consists of a single graph with an edge density of 0.2. Top row shows a case with an edge density of 0.1, and the bottom row shows a case with an edge density of 0.4.</i>
                    </center>
                    </td>
                </tr>
            </table>
            <table align=center width=1000px>
               <tr>
                 <td align=center width=900px>
                 <center>
                 <span style="font-size:20px"><a href="./resources/analysis_flocking.png"><img src = "./resources/analysis_flocking.png" width="900px"></img></href></a>
                 </span>
                 </center>
                 </td>
             </tr>
            </table>
            <table align=center width=1000px>>
                <tr>
                    <td width=600px>
                      <center>
                          <span style="font-size:18px"><i> Multi-robot flocking task: Mean Absolute Error between ground-truth and identified weighted adjacency matrices as a function of the edge density. Each configuration is run 20 times, computing the mean and standard deviation. Diamond dashed lines are the state-of-the-art (reference [28] in the paper), whereas the circle solid lines are ours. Our proposed approach surpasses the state-of-the-art in more than one order of magnitude for all the configurations. Compared to the formation task, the learned neural network achieves a good performance for the different edge densities because the training set is diverse in this aspect.</i>
                    </center>
                    </td>
                </tr>
            </table>
            <table align=center width=1000px>
               <tr>
                 <td align=center width=1000px>
                 <center>
                 <span style="font-size:20px"><a href="./resources/ground_truth_1.png"><img src = "./resources/ground_truth_1.png" width="230px"></img></href></a>
                     <a href="./resources/discovered_1.png"><img src = "./resources/discovered_1.png" width="230px"></img></href></a>
                     <a href="./resources/difference_1.png"><img src = "./resources/difference_1.png" width="230px"></img></href></a>
                 </span>
                 </center>
                 </td>
             </tr>
            </table>
            <table align=center width=1000px>
               <tr>
                 <td align=center width=1000px>
                 <center>
                 <span style="font-size:20px"><a href="./resources/ground_truth_2.png"><img src = "./resources/ground_truth_2.png" width="230px"></img></href></a>
                     <a href="./resources/discovered_2.png"><img src = "./resources/discovered_2.png" width="230px"></img></href></a>
                     <a href="./resources/difference_2.png"><img src = "./resources/difference_2.png" width="230px"></img></href></a>
                 </span>
                 </center>
                 </td>
             </tr>
            </table>
            <table align=center width=1000px>
               <tr>
                 <td align=center width=1000px>
                 <center>
                 <span style="font-size:20px"><a href="./resources/ground_truth_3.png"><img src = "./resources/ground_truth_3.png" width="230px"></img></href></a>
                     <a href="./resources/discovered_3.png"><img src = "./resources/discovered_3.png" width="230px"></img></href></a>
                     <a href="./resources/difference_3.png"><img src = "./resources/difference_3.png" width="230px"></img></href></a>
                 </span>
                 </center>
                 </td>
             </tr>
            </table>
            <table align=center width=1000px>>
                <tr>
                    <td width=600px>
                      <center>
                          <span style="font-size:18px"><i> Multi-robot flocking task: The relative value among the discovered weights is correctly identified, whereas the value of these weights with respect to the ground-truth vary depending on the edge density of the graph. For sparse, medium and dense graphs the identified weights tend to be lower, similar and greater than in the ground-truth graph. Besides, the neural network predicts a greater number of cliques, as in the middle row of the figure. These behaviors require further investigation. </i>
                    </center>
                    </td>
                </tr>
            </table>

                <center><h1>Citation</h1></center>
            <table align=center width=800px>
              <tr><center> <br>
                          <span style="font-size:18px"><i>If you find our papers/code useful for your research, please cite our work as follows. </i>
              <br>
              </center></tr>
              <tr><left> <br>
                          <span style="font-size:18px">E. Sebastian, T. Duong, N. Atanasov, E. Montijano, C. Sagues. <a href='https://github.com/EduardoSebastianRodriguez/LIGMRS'>Learning to Identify Graphs from Node Trajectories in Multi-Robot Networks</a>. Under review at IEEE MRS 2023.


              <br><br>
                              <code>@inproceedings{sebastian23LIGMRS,
                                    <br>
                                    author = {Eduardo Sebasti\'{a}n AND Thai Duong AND Nikolay Atanasov AND Eduardo Montijano AND Carlos Sag\"{u}\'{e}s},
                                  <br>
                                  title = {{Learning to Identify Graphs from Node Trajectories in Multi-Robot Networks}},
                                  <br>
                                    booktitle={IEEE International Symposium on Multi-robot \& Multi-agent Systems},
                                  <br>
                                    pages={1--7},
                                   <br>
                                    year = {2023}
                                    }
                              </code>
              </left></tr>
                  <br><br>

          </table>
            <br>
          <hr>

            <table align=center width=1100px>
                <tr>
                    <td>
                      <left>
                <center><h1>Acknowledgements</h1></center>
                This work has been supported by NSF CCF-2112665 (TILOS) and via Spanish projects PID2021-125514NB-I00, PID2021-124137OBI00 and TED2021-130224B-I00 funded by MCIN/AEI/10.13039/501100011033, by ERDF A way of making Europe and by the European Union NextGenerationEU/PRTR, DGA T45-23R, and Spanish grant FPU19-05700 and EST22/00253.
                <br>
                <br>
                This webpage template was borrowed from <a href="https://thaipduong.github.io/SE3HamDL/">https://thaipduong.github.io/SE3HamDL/</a>.
            </left>
        </td>
        </tr>
        </table>
        <br><br>

</body>
</html>